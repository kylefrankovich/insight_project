{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM image classification using RGB color space as feature vector\n",
    "\n",
    "source: https://gist.github.com/gcardone/c49e3f66dc83be33666d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Images binary classifier based on scikit-learn SVM classifier.\n",
    "It uses the RGB color space as feature vector.\n",
    "'''\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import urllib\n",
    "import urllib.request\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_directory(directory):\n",
    "    '''Returns an array of feature vectors for all the image files in a\n",
    "    directory (and all its subdirectories). Symbolic links are ignored.\n",
    "    Args:\n",
    "      directory (str): directory to process.\n",
    "    Returns:\n",
    "      list of list of float: a list of feature vectors.\n",
    "    '''\n",
    "    training = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            img_feature = process_image_file(file_path)\n",
    "            if img_feature:\n",
    "                training.append(img_feature)\n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image_file(image_path):\n",
    "    '''Given an image path it returns its feature vector.\n",
    "    Args:\n",
    "      image_path (str): path of the image file to process.\n",
    "    Returns:\n",
    "      list of float: feature vector on success, None otherwise.\n",
    "    '''\n",
    "    image_fp = BytesIO(open(image_path, 'rb').read())\n",
    "    try:\n",
    "        image = Image.open(image_fp)\n",
    "        return process_image(image)\n",
    "    except IOError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image_url(image_url):\n",
    "    '''Given an image URL it returns its feature vector\n",
    "    Args:\n",
    "      image_url (str): url of the image to process.\n",
    "    Returns:\n",
    "      list of float: feature vector.\n",
    "    Raises:\n",
    "      Any exception raised by urllib2 requests.\n",
    "      IOError: if the URL does not point to a valid file.\n",
    "    '''\n",
    "#     parsed_url = urlparse(image_url)\n",
    "#     request = urllib.request.urlopen(image_url)\n",
    "#     # set a User-Agent and Referer to work around servers that block a typical\n",
    "#     # user agents and hotlinking. Sorry, it's for science!\n",
    "#     request.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux ' \\\n",
    "#             'x86_64; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
    "#     request.add_header('Referrer', parsed_url.netloc)\n",
    "#     # Wrap network data in StringIO so that it looks like a file\n",
    "#     net_data = StringIO(urllib.build_opener().open(request).read())\n",
    "#     image = Image.open(net_data)\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    return process_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image, blocks=4):\n",
    "    '''Given a PIL Image object it returns its feature vector.\n",
    "    Args:\n",
    "      image (PIL.Image): image to process.\n",
    "      blocks (int, optional): number of block to subdivide the RGB space into.\n",
    "    Returns:\n",
    "      list of float: feature vector if successful. None if the image is not\n",
    "      RGB.\n",
    "    '''\n",
    "    if not image.mode == 'RGB':\n",
    "        return None\n",
    "    feature = [0] * blocks * blocks * blocks\n",
    "    pixel_count = 0\n",
    "    for pixel in image.getdata():\n",
    "        ridx = int(pixel[0]/(256/blocks))\n",
    "        gidx = int(pixel[1]/(256/blocks))\n",
    "        bidx = int(pixel[2]/(256/blocks))\n",
    "        idx = ridx + gidx * blocks + bidx * blocks * blocks\n",
    "        feature[idx] += 1\n",
    "        pixel_count += 1\n",
    "    return [x/pixel_count for x in feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_usage():\n",
    "    '''Prints how to use this program\n",
    "    '''\n",
    "    print(\"Usage: %s [class A images directory] [class B images directory]\" %\n",
    "            sys.argv[0])\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_path_a, training_path_b, print_metrics=True):\n",
    "    '''Trains a classifier. training_path_a and training_path_b should be\n",
    "    directory paths and each of them should not be a subdirectory of the other\n",
    "    one. training_path_a and training_path_b are processed by\n",
    "    process_directory().\n",
    "    Args:\n",
    "      training_path_a (str): directory containing sample images of class A.\n",
    "      training_path_b (str): directory containing sample images of class B.\n",
    "      print_metrics  (boolean, optional): if True, print statistics about\n",
    "        classifier performance.\n",
    "    Returns:\n",
    "      A classifier (sklearn.svm.SVC).\n",
    "    '''\n",
    "    if not os.path.isdir(training_path_a):\n",
    "        raise IOError('%s is not a directory' % training_path_a)\n",
    "    if not os.path.isdir(training_path_b):\n",
    "        raise IOError('%s is not a directory' % training_path_b)\n",
    "    time_now = time.asctime( time.localtime(time.time()) )\n",
    "    print('\\n')\n",
    "    print(\"current/start time :\", time_now)\n",
    "    print('processing training path A...')\n",
    "    training_a = process_directory(training_path_a)\n",
    "    \n",
    "    time_now = time.asctime( time.localtime(time.time()) )    \n",
    "    print('\\n')\n",
    "    print(\"current time :\", time_now)\n",
    "    print('processing training path B...')\n",
    "    training_b = process_directory(training_path_b)\n",
    "    \n",
    "    # data contains all the training data (a list of feature vectors)\n",
    "    data = training_a + training_b\n",
    "    \n",
    "    # target is the list of target classes for each feature vector: a '1' for\n",
    "    # class A and '0' for class B\n",
    "    target = [1] * len(training_a) + [0] * len(training_b)\n",
    "    \n",
    "    # split training data in a train set and a test set. The test set will\n",
    "    # containt 20% of the total\n",
    "    x_train, x_test, y_train, y_test = cross_validation.train_test_split(data,\n",
    "            target, test_size=0.20)\n",
    "    # define the parameter search space\n",
    "    parameters = {'kernel': ['linear', 'rbf'], 'C': [1, 10, 100, 1000],\n",
    "            'gamma': [0.01, 0.001, 0.0001]}\n",
    "    \n",
    "    # search for the best classifier within the search space and return it\n",
    "    time_now = time.asctime( time.localtime(time.time()) )\n",
    "    print('\\n')\n",
    "    print(\"current time :\", time_now)\n",
    "    print('training classifier. grab some coffee...')\n",
    "    clf = grid_search.GridSearchCV(svm.SVC(), parameters).fit(x_train, y_train)\n",
    "    classifier = clf.best_estimator_\n",
    "    if print_metrics:\n",
    "        print()\n",
    "        print('Parameters:', clf.best_params_)\n",
    "        print()\n",
    "        print('Best classifier score')\n",
    "        print(metrics.classification_report(y_test,\n",
    "            classifier.predict(x_test)))\n",
    "        \n",
    "    time_now = time.asctime( time.localtime(time.time()) )\n",
    "    print('\\n')\n",
    "    print(\"end time:\", time_now)\n",
    "    print('done!')\n",
    "    return classifier, data, target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(training_path_a, training_path_b):\n",
    "    '''Main function. Trains a classifier and allows to use it on images\n",
    "    downloaded from the Internet.\n",
    "    Args:\n",
    "      training_path_a (str): directory containing sample images of class A.\n",
    "      training_path_b (str): directory containing sample images of class B.\n",
    "    '''\n",
    "    print('Training classifier...')\n",
    "    classifier = train(training_path_a, training_path_b)\n",
    "    while True:\n",
    "        try:\n",
    "            print(\"Input an image url (enter to exit): \"),\n",
    "            image_url = raw_input()\n",
    "            if not image_url:\n",
    "                break\n",
    "            features = process_image_url(image_url)\n",
    "            print(classifier.predict(features))\n",
    "        except (KeyboardInterrupt, EOFError):\n",
    "            break\n",
    "        except:\n",
    "            exception = sys.exc_info()[0]\n",
    "            print(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tattoo_directory_path = '/Users/kylefrankovich/Desktop/training_data/tattoo'\n",
    "non_tattoo_directory_path = '/Users/kylefrankovich/Desktop/training_data/non_tattoo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training SVM on full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "current/start time : Wed Jan 24 18:00:19 2018\n",
      "processing training path A...\n",
      "\n",
      "\n",
      "current time : Wed Jan 24 18:22:05 2018\n",
      "processing training path B...\n",
      "\n",
      "\n",
      "current time : Wed Jan 24 18:42:49 2018\n",
      "training classifier. grab some coffee...\n",
      "\n",
      "Parameters: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Best classifier score\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.63      0.65       197\n",
      "          1       0.67      0.70      0.68       203\n",
      "\n",
      "avg / total       0.67      0.67      0.67       400\n",
      "\n",
      "\n",
      "\n",
      "end time: Wed Jan 24 18:43:00 2018\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "classifier, data, train = train(tattoo_directory_path,non_tattoo_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "current/start time : Wed Jan 24 11:39:17 2018\n",
      "processing training path A...\n",
      "\n",
      "\n",
      "current time : Wed Jan 24 11:50:38 2018\n",
      "processing training path B...\n",
      "\n",
      "\n",
      "current time : Wed Jan 24 11:50:38 2018\n",
      "training classifier. grab some coffee...\n",
      "\n",
      "Parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "\n",
      "Best classifier score\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.55      0.63       115\n",
      "          1       0.55      0.74      0.63        85\n",
      "\n",
      "avg / total       0.66      0.63      0.63       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classifier trained on half of our data:\n",
    "classifier = train(tattoo_directory_path, non_tattoo_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "\n",
    "'/Users/kylefrankovich/Desktop/training_data/tattoo'\n",
    "\n",
    "filename = '/Users/kylefrankovich/Desktop/insight_project/trained_models/svm_model_1000.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = 'https://d3qi0qp55mx5f5.cloudfront.net/www/i/homepage/spotlight/urban-chicago-spotlight.jpg?mtime=1473347326'\n",
    "features = process_image_url(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save features and target:\n",
    "# test out saving features/target w/ smalle datasets:\n",
    "features_filename = '/Users/kylefrankovich/Desktop/training_data/features.csv'\n",
    "target_filename = '/Users/kylefrankovich/Desktop/training_data/target.csv'\n",
    "\n",
    "\n",
    "# export list (features):\n",
    "with open(features_filename, 'wb') as fp:\n",
    "    pickle.dump(data, fp)\n",
    "    \n",
    "# export list (target):\n",
    "with open(target_filename, 'wb') as fp:\n",
    "    pickle.dump(train, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read back in:\n",
    "with open (features_filename, 'rb') as fp:\n",
    "    itemlist = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23405692729766803,\n",
       " 0.01912551440329218,\n",
       " 1.7146776406035666e-05,\n",
       " 0.0,\n",
       " 0.00023662551440329217,\n",
       " 0.010528120713305899,\n",
       " 0.0007098765432098765,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.008285322359396434,\n",
       " 0.0005006858710562414,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.006841563786008231,\n",
       " 0.3069650205761317,\n",
       " 0.039152949245541836,\n",
       " 0.0013648834019204389,\n",
       " 0.0,\n",
       " 0.0010939643347050755,\n",
       " 0.019015775034293553,\n",
       " 0.017421124828532236,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00013374485596707818,\n",
       " 0.0043621399176954736,\n",
       " 0.00038751714677640606,\n",
       " 0.00018861454046639232,\n",
       " 0.0,\n",
       " 0.004945130315500686,\n",
       " 0.014300411522633744,\n",
       " 0.05198902606310014,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.573388203017832e-05,\n",
       " 0.004478737997256516,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.02880658436214e-05,\n",
       " 0.00020576131687242798,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.08641975308642e-05,\n",
       " 0.2535665294924554]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[0.4441337584825443, 0.07742314610416155, 0.012683958793230317, 1.02199329572398e-06, 1.328591284441174e-05, 0.022704603057803942, 0.0034563813261385004, 2.04398659144796e-06, 0.0, 0.0, 0.00020542065244051998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0025304554002125745, 0.015145940642629384, 0.000972937617529229, 3.8835745237511245e-05, 0.00015432098765432098, 0.20251819148066388, 0.017492437249611643, 0.0019765350339301774, 0.0, 1.02199329572398e-06, 0.0186881694056087, 0.00022688251165072358, 0.0, 0.0, 0.0, 1.02199329572398e-06, 0.0, 1.02199329572398e-06, 1.02199329572398e-05, 0.0, 0.0, 0.005800833946529311, 0.016169977924944814, 9.095740331943422e-05, 0.0, 9.19793966151582e-06, 0.06100482380835582, 0.010996647861990025, 0.0, 0.0, 0.0, 0.039928256070640177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.04398659144796e-06, 1.02199329572398e-06, 0.0, 0.0, 0.0007787588913416728, 0.0009279699125173739, 0.0, 0.0, 2.248385250592756e-05, 0.043885414111683424]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-4e4c5a150d3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myour_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \"\"\"\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'support_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[0.4441337584825443, 0.07742314610416155, 0.012683958793230317, 1.02199329572398e-06, 1.328591284441174e-05, 0.022704603057803942, 0.0034563813261385004, 2.04398659144796e-06, 0.0, 0.0, 0.00020542065244051998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0025304554002125745, 0.015145940642629384, 0.000972937617529229, 3.8835745237511245e-05, 0.00015432098765432098, 0.20251819148066388, 0.017492437249611643, 0.0019765350339301774, 0.0, 1.02199329572398e-06, 0.0186881694056087, 0.00022688251165072358, 0.0, 0.0, 0.0, 1.02199329572398e-06, 0.0, 1.02199329572398e-06, 1.02199329572398e-05, 0.0, 0.0, 0.005800833946529311, 0.016169977924944814, 9.095740331943422e-05, 0.0, 9.19793966151582e-06, 0.06100482380835582, 0.010996647861990025, 0.0, 0.0, 0.0, 0.039928256070640177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.04398659144796e-06, 1.02199329572398e-06, 0.0, 0.0, 0.0007787588913416728, 0.0009279699125173739, 0.0, 0.0, 2.248385250592756e-05, 0.043885414111683424]'"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(your_list[0][9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
